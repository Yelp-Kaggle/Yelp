{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('yelp_academic_dataset_review_train.csv')\n",
    "data_test = pd.read_csv('yelp_academic_dataset_review_test.csv')\n",
    "train_biz = pd.read_csv(\"yelp_academic_dataset_business_train.csv\")\n",
    "test_biz = pd.read_csv(\"yelp_academic_dataset_business_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_reviews = pd.concat([data_train.text, data_test.text])\n",
    "train_length = data_train.shape[0]\n",
    "test_length = data_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(154)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "### Start by balancing the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rating_4 = np.array(data_train[data_train.stars == 4].index)\n",
    "rating_5 = np.array(data_train[data_train.stars == 5].index)\n",
    "np.random.shuffle(rating_4)\n",
    "np.random.shuffle(rating_5)\n",
    "rating_4 = rating_4[:len(rating_4)//2]\n",
    "rating_5 = rating_5[:2*len(rating_5)//3]\n",
    "data_train_balanced = data_train.drop(rating_4)\n",
    "data_train_balanced = data_train.drop(rating_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Then use bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', max_features=10000)\n",
    "count_vect.fit(data_train_balanced.text)\n",
    "X_train_counts = count_vect.transform(data_train.text)\n",
    "X_test_counts = count_vect.transform(data_test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Then SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_selector = TruncatedSVD(n_components=100)\n",
    "X_train_best = feature_selector.fit_transform(X_train_counts, data_train.stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Then classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clfr = RandomForestClassifier(verbose=2, n_estimators=20, n_jobs=-1)\n",
    "clfl = LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "                        fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "                        multi_class='ovr', penalty='l2', random_state=None,\n",
    "                        solver='liblinear', tol=0.0001, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "cv_preds = cross_val_predict(clf, X_train_counts, data_train.stars, cv=10, n_jobs=-1)\n",
    "data_train['cv_preds'] = cv_preds\n",
    "grouped = data_train.groupby(\"business_id\").mean()\n",
    "compare = train_biz.merge(grouped, left_on='business_id', right_index=True)\n",
    "np.sqrt(np.mean((compare.stars_x - compare.cv_preds)**2))\n",
    "\n",
    "clf.fit(X_train_counts, data_train.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(compare.stars_x, compare.cv_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Trying Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.doc2vec.Doc2Vec(min_count=1, window=10, size=1000, sample=1e-4, negative=5, workers=4, iter=10)\n",
    "print(\"Preprocessing data\")\n",
    "\n",
    "train_reviews = []\n",
    "for i, review in enumerate(data_train.text):\n",
    "    if i % 10000 == 0 and i != 0:\n",
    "        print(i)\n",
    "    preprocessed = gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(review), [i])\n",
    "    train_reviews.append(preprocessed)\n",
    "    \n",
    "test_reviews = []\n",
    "for review in data_test.text:\n",
    "    if i % 10000 == 0 and i != 0:\n",
    "        print(i)\n",
    "    preprocessed = gensim.utils.simple_preprocess(review)\n",
    "    test_reviews.append(preprocessed)    \n",
    "    \n",
    "print(\"Building Vocab\")\n",
    "\n",
    "model.build_vocab(train_reviews)\n",
    "model.train(train_reviews, total_examples=len(train_reviews), epochs=model.iter)\n",
    "\n",
    "print(\"Inferring Vectors\")\n",
    "X_train = np.array([model.infer_vector(review.words) for review in train_reviews])\n",
    "X_test = np.array([model.infer_vector(review) for review in test_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = clfr\n",
    "cv_preds = cross_val_predict(clf, X_train, data_train.stars, cv=10)\n",
    "data_train['cv_preds'] = cv_preds\n",
    "grouped = data_train.groupby(\"business_id\").mean()\n",
    "compare = train_biz.merge(grouped, left_on='business_id', right_index=True)\n",
    "np.sqrt(np.mean((compare.stars_x - compare.cv_preds)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_price_range(attributes):\n",
    "    if type(attributes) == str and 'RestaurantsPriceRange2' in attributes:\n",
    "        return int(attributes[attributes.index('RestaurantsPriceRange2')+24])\n",
    "    return np.nan\n",
    "\n",
    "def get_cred_info(attributes):\n",
    "    if type(attributes) == str and 'BusinessAcceptsCreditCards' in attributes:\n",
    "        index = attributes.index('BusinessAcceptsCreditCards')\n",
    "        return True if attributes[index+28] == \"T\" else False\n",
    "    return np.nan\n",
    "\n",
    "def get_reservations(attributes):\n",
    "    if type(attributes) == str and 'RestaurantsReservations' in attributes:\n",
    "        index = attributes.index('RestaurantsReservations')\n",
    "        return True if attributes[index+25] == \"T\" else False\n",
    "    return np.nan\n",
    "\n",
    "def get_takeout(attributes):\n",
    "    if type(attributes) == str and 'RestaurantsTakeOut' in attributes:\n",
    "        index = attributes.index('RestaurantsTakeOut')\n",
    "        return True if attributes[index+20] == \"T\" else False\n",
    "    return np.nan\n",
    "\n",
    "def get_delivery(attributes):\n",
    "    if type(attributes) == str and 'RestaurantsDelivery' in attributes:\n",
    "        index = attributes.index('RestaurantsDelivery')\n",
    "        return True if attributes[index+21] == \"T\" else False\n",
    "    return np.nan\n",
    "\n",
    "train_price_range = train_biz.attributes.apply(get_price_range)\n",
    "test_price_range = test_biz.attributes.apply(get_price_range)\n",
    "train_credit_cards = train_biz.attributes.apply(get_cred_info)\n",
    "test_credit_cards = test_biz.attributes.apply(get_cred_info)\n",
    "train_reservations = train_biz.attributes.apply(get_cred_info)\n",
    "test_reservations = test_biz.attributes.apply(get_cred_info)\n",
    "train_takeout = train_biz.attributes.apply(get_takeout)\n",
    "test_takeout = test_biz.attributes.apply(get_takeout)\n",
    "train_delivery = train_biz.attributes.apply(get_delivery)\n",
    "test_delivery = test_biz.attributes.apply(get_delivery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv_preds = cross_val_predict(clf, X_train_counts, data_train.stars, cv=10)\n",
    "data_train['preds'] = cv_preds\n",
    "grouped = data_train.groupby(\"business_id\").mean()\n",
    "X_train = train_biz.merge(grouped, left_on='business_id', right_index=True)[[\"preds\", \"stars_y\"]]\n",
    "X_train, y_train = X_train.drop(\"stars_y\", axis=1), X_train.stars_y\n",
    "\n",
    "clf.fit(X_train_counts, data_train.stars)\n",
    "data_test['preds'] = clf.predict(X_test_counts)\n",
    "grouped = data_test.groupby(\"business_id\").mean()\n",
    "X_test = test_biz.merge(grouped, left_on='business_id', right_index=True)[[\"preds\"]]\n",
    "biz_ids = test_biz.merge(grouped, left_on='business_id', right_index=True).business_id\n",
    "\n",
    "X_train['price_range'] = train_price_range\n",
    "X_train['credit_cards'] = train_credit_cards\n",
    "X_train['reservations'] = train_reservations\n",
    "X_train['takeout'] = train_takeout\n",
    "X_train['delivery'] = train_delivery\n",
    "\n",
    "X_test['price_range'] = test_price_range\n",
    "X_test['credit_cards'] = test_credit_cards\n",
    "X_test['reservations'] = test_reservations\n",
    "X_test['takeout'] = test_takeout\n",
    "X_test['delivery'] = test_delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = Imputer().fit_transform(X_train)\n",
    "X_test = Imputer().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34903295099797743"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2 = LinearRegression()\n",
    "clf_2.fit(X_train, y_train)\n",
    "clf_2.predict(X_test)\n",
    "\n",
    "cv_preds = cross_val_predict(clf_2, X_train, y_train, cv=10)\n",
    "np.sqrt(np.mean((cv_preds - y_train)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'business_id': biz_ids, 'score': clf_2.predict(X_test)})\n",
    "merged = final_df.merge(all_test, on=\"business_id\")\n",
    "merged = merged.set_index('business_id')\n",
    "merged['stars'] = merged.score\n",
    "merged[['stars']].to_csv(\"Sub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame([{\"business_id\": biz, \"stars\": pred_per_buisiness[biz]} for biz in test_biz.business_id])\n",
    "pred_df = pred_df.set_index(\"business_id\")\n",
    "pred_df.to_csv(\"Submission\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "importances = [pair for pair in enumerate(clf.feature_importances_)]\n",
    "sorted_importances = sorted(importances, key = lambda x: x[1], reverse=True)\n",
    "top_ten = [x[0] for x in sorted_importances[:10]]\n",
    "feature_lookup = {count_vect.vocabulary_[key]: key for key in count_vect.vocabulary_}\n",
    "[feature_lookup[feature] for feature in top_ten]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
